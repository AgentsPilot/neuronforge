// lib/agentkit/runAgentKit.ts

import { openai, AGENTKIT_CONFIG } from './agentkitClient';
import { convertPluginsToTools, getPluginContextPrompt } from './convertPlugins';
import { PluginExecuterV2 } from '@/lib/server/plugin-executer-v2';
import type { ChatCompletionMessageParam } from 'openai/resources/chat/completions';
import { OpenAIProvider } from '@/lib/ai/providers/openaiProvider';
import { AuditTrailService } from '@/lib/services/AuditTrailService';
import { AUDIT_EVENTS } from '@/lib/audit/events';

// Note: AI Analytics tracking happens automatically via OpenAIProvider and BaseProvider
// No need to initialize AIAnalyticsService or Supabase separately here

// Initialize Audit Trail
const auditTrail = AuditTrailService.getInstance();

export interface AgentKitExecutionResult {
  success: boolean;
  response: string;
  toolCalls: Array<{
    plugin: string;
    action: string;
    parameters: any;
    result: any;
    success: boolean;
  }>;
  tokensUsed: {
    prompt: number;
    completion: number;
    total: number;
  };
  executionTime: number;
  iterations: number;
  error?: string;
}

/**
 * Generate output instructions from output_schema
 * If output_schema is missing or empty, fallback to legacy trigger_condintion logic
 */
function generateOutputInstructions(outputSchema: any[], triggerCondition?: any): string {
  // Backward compatibility: If no output_schema, use legacy logic
  if (!outputSchema || outputSchema.length === 0) {
    console.log('âš ï¸ No output_schema found, using legacy trigger_condintion logic');
    const triggerConfig = triggerCondition?.error_handling || {};
    const deliveryMethod = triggerConfig.on_failure || 'alert';

    if (deliveryMethod === 'email') {
      return `\n\n## IMPORTANT: Result Delivery
- After completing the task, you MUST send the results via email using the google-mail send_email function
- Send the email to the user with a clear summary of what was accomplished
- Include all relevant details, results, and next steps in the email body
- The email subject should clearly describe the task completed`;
    } else {
      return `\n\n## IMPORTANT: Result Delivery
- Complete the task and return a clear summary
- Do NOT send emails unless explicitly requested in the task
- Return results directly for dashboard display`;
    }
  }

  // NEW: Schema-driven output instructions
  // Filter out error-only outputs (they trigger only on failure)
  const activeOutputs = outputSchema.filter(o => !o.config?.trigger || o.config.trigger !== 'on_error');

  if (activeOutputs.length === 0) {
    return `\n\n## Output Instructions:\n- Return results for dashboard display`;
  }

  const instructions = activeOutputs.map(output => {
    switch (output.type) {
      case 'EmailDraft':
        return `- Send results via email${output.config?.recipient ? ` to ${output.config.recipient}` : ''}`;

      case 'SummaryBlock':
        const format = output.format || 'text';
        if (format === 'table') {
          return `- Format results as an HTML table with clear columns and rows`;
        } else if (format === 'list') {
          return `- Format results as a bulleted or numbered list`;
        } else if (format === 'markdown') {
          return `- Format results using markdown formatting`;
        } else if (format === 'json') {
          return `- Format results as JSON data structure`;
        } else if (format === 'html') {
          return `- Format results as HTML content`;
        } else {
          return `- Provide a clear summary of results`;
        }

      case 'PluginAction':
        return `- Save/send results using ${output.plugin || 'the appropriate plugin'}`;

      case 'Alert':
        return `- Return results for dashboard display`;

      default:
        return `- ${output.description || 'Provide results'}`;
    }
  }).join('\n');

  return `\n\n## Output Requirements:\n${instructions}`;
}

/**
 * Main AgentKit execution function
 *
 * Orchestrates agent execution using OpenAI's function calling with the V2 Plugin System.
 * This replaces the complex 8-phase custom orchestration with OpenAI's native capabilities.
 *
 * Flow:
 * 1. Convert V2 plugin definitions to OpenAI tools
 * 2. Build enhanced system prompt with plugin context
 * 3. Execute function calling loop (up to maxIterations)
 * 4. For each tool call, execute via PluginExecuterV2
 * 5. Return results to OpenAI for final response
 *
 * @param userId - User ID for plugin connections
 * @param agent - Agent configuration from Supabase agents table
 * @param userInput - User's input/request
 * @returns Execution result with response, tool calls, and metrics
 */
export async function runAgentKit(
  userId: string,
  agent: {
    id: string;
    agent_name: string;
    system_prompt?: string;
    enhanced_prompt?: string;
    user_prompt: string;
    plugins_required: string[];
    input_schema?: any;
    output_schema?: any;
    trigger_condintion?: any; // Notification preference: email or alert/dashboard
  },
  userInput: string,
  inputValues?: Record<string, any>, // Input values from agent_configurations
  sessionId?: string // NEW: Session ID for analytics tracking
): Promise<AgentKitExecutionResult> {
  const startTime = Date.now();
  const toolCalls: AgentKitExecutionResult['toolCalls'] = [];

  console.log(`ðŸ¤– AgentKit: Starting execution for "${agent.agent_name}"`);
  console.log(`ðŸ“¦ Required plugins: ${agent.plugins_required.join(', ')}`);
  console.log(`ðŸ‘¤ User: ${userId}`);

  // Initialize OpenAI Provider with automatic analytics tracking via BaseProvider
  const openaiProvider = new OpenAIProvider(process.env.OPENAI_API_KEY!);

  // Log execution start to audit trail
  await auditTrail.log({
    action: AUDIT_EVENTS.AGENTKIT_EXECUTION_STARTED,
    entityType: 'agent',
    entityId: agent.id,
    userId: userId,
    resourceName: agent.agent_name,
    details: {
      sessionId: sessionId,
      plugins_required: agent.plugins_required,
      execution_mode: 'agentkit',
      model: AGENTKIT_CONFIG.model,
      user_input: userInput.substring(0, 200), // First 200 chars
      has_input_values: inputValues ? Object.keys(inputValues).length > 0 : false,
      trigger_condition: agent.trigger_condintion
    },
    severity: 'info'
  });

  try {
    // STEP 1: Convert V2 plugins to OpenAI tools
    const tools = await convertPluginsToTools(userId, agent.plugins_required);

    if (tools.length === 0) {
      console.warn('âš ï¸ AgentKit: No plugins are connected');
      return {
        success: false,
        response: "No plugins are connected. Please connect the required plugins in Settings â†’ Connected Apps to use this agent.",
        toolCalls: [],
        tokensUsed: { prompt: 0, completion: 0, total: 0 },
        executionTime: Date.now() - startTime,
        iterations: 0,
        error: "NO_PLUGINS_CONNECTED"
      };
    }

    console.log(`ðŸ”§ AgentKit: Loaded ${tools.length} available actions across ${agent.plugins_required.length} plugins`);
    console.log('\nðŸ“Š AGENTKIT DEBUG - TOOLS AVAILABLE:', JSON.stringify(tools, null, 2));

    // STEP 2: Build enhanced system prompt with plugin context
    const pluginContext = await getPluginContextPrompt(userId, agent.plugins_required);

    // NEW: Generate output instructions from output_schema (or fallback to legacy)
    const outputInstructions = generateOutputInstructions(agent.output_schema, agent.trigger_condintion);

    // Add current date/time context (critical for time-based operations)
    // AI models don't have real-time access - we must provide the current timestamp
    const now = new Date();
    const currentDateTime = now.toISOString();
    const readableDate = now.toLocaleDateString('en-US', {
      weekday: 'long',
      year: 'numeric',
      month: 'long',
      day: 'numeric'
    });

    const systemPrompt = `${agent.system_prompt || agent.enhanced_prompt || agent.user_prompt}

${pluginContext}

## Current Date & Time
Today is: ${readableDate}
Current timestamp: ${currentDateTime}

IMPORTANT: When the user refers to "today", "now", "this week", etc., use the date/time above as reference.

## Instructions
- Use the available functions to accomplish the user's request
- Do NOT provide generic advice or suggestions - execute actual actions using the connected services
- If an action fails, try an alternative approach or inform the user clearly about what went wrong
- Provide specific results based on the actual data returned from function calls
- Always use the most appropriate function for the task${outputInstructions}`;

    console.log(`ðŸ“¬ AgentKit: Output instructions generated from schema`);
    console.log(`ðŸ“… AgentKit: Current date context: ${readableDate}`);
    console.log('\nðŸ“Š AGENTKIT DEBUG - SYSTEM PROMPT:\n', systemPrompt);

    // STEP 3: Build user message with input values context
    let enhancedUserInput = userInput;

    // If input values are provided (from agent_configurations), add them to context
    if (inputValues && Object.keys(inputValues).length > 0) {
      enhancedUserInput = `${userInput}

## Available Input Data:
${Object.entries(inputValues)
  .map(([key, value]) => `- **${key}**: ${typeof value === 'object' ? JSON.stringify(value) : value}`)
  .join('\n')}

Please use these input values when executing the task.`;

      console.log(`ðŸ“‹ AgentKit: Using ${Object.keys(inputValues).length} input values from configuration`);
    }

    // STEP 4: Initialize conversation
    const messages: ChatCompletionMessageParam[] = [
      { role: "system", content: systemPrompt },
      { role: "user", content: enhancedUserInput }
    ];

    console.log('\nðŸ“Š AGENTKIT DEBUG - USER INPUT:\n', enhancedUserInput);
    console.log('\nðŸ“Š AGENTKIT DEBUG - INPUT VALUES:\n', JSON.stringify(inputValues, null, 2));
    console.log('\nðŸ“Š AGENTKIT DEBUG - AGENT CONFIG:', {
      agent_id: agent.id,
      agent_name: agent.agent_name,
      plugins_required: agent.plugins_required,
      trigger_condintion: agent.trigger_condintion,
      input_schema: agent.input_schema,
      output_schema: agent.output_schema
    });

    // STEP 5: Function calling loop
    let iteration = 0;
    let totalTokens = { prompt: 0, completion: 0, total: 0 };
    const pluginExecuter = await PluginExecuterV2.getInstance();

    while (iteration < AGENTKIT_CONFIG.maxIterations) {
      iteration++;
      console.log(`\nðŸ”„ AgentKit: Iteration ${iteration}/${AGENTKIT_CONFIG.maxIterations}`);

      // Log the request being sent to OpenAI
      console.log('\nðŸ“Š AGENTKIT DEBUG - OPENAI REQUEST:', {
        model: AGENTKIT_CONFIG.model,
        temperature: AGENTKIT_CONFIG.temperature,
        tools_count: tools.length,
        messages_count: messages.length,
        iteration: iteration
      });

      // Call OpenAI with function calling enabled + automatic analytics tracking via BaseProvider
      const completion = await openaiProvider.chatCompletion(
        {
          model: AGENTKIT_CONFIG.model,
          messages: messages,
          tools: tools,
          tool_choice: "auto", // Let OpenAI decide when to use tools
          temperature: AGENTKIT_CONFIG.temperature,
        },
        {
          userId: userId,
          sessionId: sessionId,
          feature: 'agentkit_execution',
          component: 'run-agentkit',
          workflow_step: `iteration_${iteration}`,
          category: 'agent_execution',
          activity_type: 'agent_execution',
          activity_name: `${agent.agent_name} - Iteration ${iteration}`, // Temporary, will be enhanced below
          agent_id: agent.id,
          activity_step: `iteration_${iteration}_of_${AGENTKIT_CONFIG.maxIterations}`
        }
      );

      // Track token usage
      if (completion.usage) {
        totalTokens.prompt += completion.usage.prompt_tokens;
        totalTokens.completion += completion.usage.completion_tokens;
        totalTokens.total += completion.usage.total_tokens;
      }

      const message = completion.choices[0].message;

      console.log('\nðŸ“Š AGENTKIT DEBUG - OPENAI RESPONSE:', {
        has_content: !!message.content,
        content_length: message.content?.length || 0,
        has_tool_calls: !!message.tool_calls,
        tool_calls_count: message.tool_calls?.length || 0,
        tokens_used: completion.usage
      });

      // Check if OpenAI wants to call any tools
      if (!message.tool_calls || message.tool_calls.length === 0) {
        // No more tool calls - execution is complete!
        console.log(`âœ… AgentKit: Completed in ${iteration} iterations`);
        console.log(`ðŸ’° Tokens used: ${totalTokens.total} (${totalTokens.prompt} prompt + ${totalTokens.completion} completion)`);
        console.log('\nðŸ“Š AGENTKIT DEBUG - FINAL RESPONSE:\n', message.content);

        // NOTE: Token tracking happens automatically via openaiProvider.chatCompletion() at line 294
        // No manual tracking needed here to avoid duplicates

        // Log successful completion to audit trail
        await auditTrail.log({
          action: AUDIT_EVENTS.AGENTKIT_EXECUTION_COMPLETED,
          entityType: 'agent',
          entityId: agent.id,
          userId: userId,
          resourceName: agent.agent_name,
          details: {
            sessionId: sessionId,
            iterations: iteration,
            total_tokens: totalTokens.total,
            execution_time_ms: Date.now() - startTime,
            tool_calls_count: toolCalls.length,
            plugins_used: [...new Set(toolCalls.map(tc => tc.plugin))],
            response_length: message.content?.length || 0
          },
          severity: 'info'
        });

        return {
          success: true,
          response: message.content || "Task completed successfully.",
          toolCalls: toolCalls,
          tokensUsed: totalTokens,
          executionTime: Date.now() - startTime,
          iterations: iteration
        };
      }

      // Add assistant's message with tool calls to conversation history
      messages.push(message);

      // NOTE: Token tracking already happened automatically via openaiProvider.chatCompletion() at line 294
      // No manual tracking needed here to avoid duplicates

      // STEP 5: Execute tool calls using V2 Plugin System
      console.log(`ðŸ”Œ AgentKit: Executing ${message.tool_calls.length} tool call(s)...`);

      for (const toolCall of message.tool_calls) {
        // Type guard to ensure we have a function tool call
        if (toolCall.type !== 'function') continue;

        // Parse function name (format: "pluginKey__actionName")
        const [pluginKey, actionName] = toolCall.function.name.split('__');

        // Parse function arguments
        let parameters: any;
        try {
          parameters = JSON.parse(toolCall.function.arguments);
        } catch (e) {
          console.error(`âŒ AgentKit: Failed to parse tool arguments for ${toolCall.function.name}:`, toolCall.function.arguments);
          parameters = {};
        }

        console.log(`  â†’ ${pluginKey}.${actionName}(${Object.keys(parameters).join(', ')})`);
        console.log('\nðŸ“Š AGENTKIT DEBUG - TOOL CALL PARAMS:', JSON.stringify(parameters, null, 2));

        try {
          // Execute using V2 PluginExecuterV2!
          // This will:
          // 1. Validate parameters against JSON Schema
          // 2. Get user connection with token refresh if needed
          // 3. Route to specific plugin executor (GmailPluginExecutor, etc.)
          // 4. Execute the action via the appropriate API
          // 5. Return formatted result with error mapping
          const result = await pluginExecuter.execute(
            userId,
            pluginKey,
            actionName,
            parameters
          );

          console.log('\nðŸ“Š AGENTKIT DEBUG - PLUGIN RESULT:', JSON.stringify(result, null, 2));

          if (result.success) {
            console.log(`    âœ“ Success: ${result.message || 'OK'}`);

            // Log successful plugin execution to audit trail
            await auditTrail.log({
              action: AUDIT_EVENTS.AGENTKIT_PLUGIN_SUCCESS,
              entityType: 'plugin',
              entityId: pluginKey,
              userId: userId,
              resourceName: `${pluginKey}.${actionName}`,
              details: {
                sessionId: sessionId,
                agent_id: agent.id,
                agent_name: agent.agent_name,
                action: actionName,
                iteration: iteration,
                parameters_count: Object.keys(parameters).length,
                result_message: result.message
              },
              severity: 'info'
            });
          } else {
            console.log(`    âœ— Failed: ${result.error || result.message}`);

            // Log failed plugin execution to audit trail
            await auditTrail.log({
              action: AUDIT_EVENTS.AGENTKIT_PLUGIN_FAILED,
              entityType: 'plugin',
              entityId: pluginKey,
              userId: userId,
              resourceName: `${pluginKey}.${actionName}`,
              details: {
                sessionId: sessionId,
                agent_id: agent.id,
                agent_name: agent.agent_name,
                action: actionName,
                iteration: iteration,
                error: result.error || result.message,
                parameters_count: Object.keys(parameters).length
              },
              severity: 'warning'
            });
          }

          // Track tool call for analytics
          toolCalls.push({
            plugin: pluginKey,
            action: actionName,
            parameters: parameters,
            result: result,
            success: result.success
          });

          // Add tool result to conversation so OpenAI can use it
          messages.push({
            role: "tool",
            tool_call_id: toolCall.id,
            content: JSON.stringify(result)
          });

        } catch (error: any) {
          console.error(`    âœ— Execution error: ${error.message}`);

          // Track failed tool call
          toolCalls.push({
            plugin: pluginKey,
            action: actionName,
            parameters: parameters,
            result: { success: false, error: error.message },
            success: false
          });

          // Add error to conversation so OpenAI can handle it intelligently
          // OpenAI might retry with different parameters or use an alternative approach
          messages.push({
            role: "tool",
            tool_call_id: toolCall.id,
            content: JSON.stringify({
              success: false,
              error: error.message || "Plugin execution failed",
              message: `The ${pluginKey}.${actionName} action failed. Please try an alternative approach or inform the user.`
            })
          });
        }
      }

      // Continue to next iteration with updated conversation
    }

    // Max iterations reached - task is too complex
    console.warn(`âš ï¸ AgentKit: Reached maximum iterations (${AGENTKIT_CONFIG.maxIterations})`);
    console.log(`ðŸ’° Tokens used: ${totalTokens.total}`);

    // Log max iterations warning to audit trail
    await auditTrail.log({
      action: AUDIT_EVENTS.AGENTKIT_MAX_ITERATIONS_REACHED,
      entityType: 'agent',
      entityId: agent.id,
      userId: userId,
      resourceName: agent.agent_name,
      details: {
        sessionId: sessionId,
        max_iterations: AGENTKIT_CONFIG.maxIterations,
        total_tokens: totalTokens.total,
        execution_time_ms: Date.now() - startTime,
        tool_calls_count: toolCalls.length,
        plugins_attempted: [...new Set(toolCalls.map(tc => tc.plugin))]
      },
      severity: 'warning'
    });

    return {
      success: false,
      response: "The task is too complex and reached the maximum number of execution steps. Please try breaking it into smaller, simpler requests.",
      toolCalls: toolCalls,
      tokensUsed: totalTokens,
      executionTime: Date.now() - startTime,
      iterations: iteration,
      error: "MAX_ITERATIONS_REACHED"
    };

  } catch (error: any) {
    console.error('âŒ AgentKit: Execution error:', error);

    // Log execution failure to audit trail
    await auditTrail.log({
      action: AUDIT_EVENTS.AGENTKIT_EXECUTION_FAILED,
      entityType: 'agent',
      entityId: agent.id,
      userId: userId,
      resourceName: agent.agent_name,
      details: {
        sessionId: sessionId,
        error_message: error.message,
        error_stack: error.stack?.substring(0, 500), // First 500 chars of stack
        execution_time_ms: Date.now() - startTime,
        tool_calls_attempted: toolCalls.length,
        plugins_used: [...new Set(toolCalls.map(tc => tc.plugin))]
      },
      severity: 'warning'
    });

    return {
      success: false,
      response: `Execution failed: ${error.message}. Please try again or contact support if the issue persists.`,
      toolCalls: toolCalls,
      tokensUsed: { prompt: 0, completion: 0, total: 0 },
      executionTime: Date.now() - startTime,
      iterations: 0,
      error: error.message
    };
  }
}
