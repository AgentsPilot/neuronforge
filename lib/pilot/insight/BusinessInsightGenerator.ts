/**
 * BusinessInsightGenerator - LLM-powered business intelligence
 *
 * Converts statistical trends into actionable business insights for non-technical users
 *
 * Features:
 * - Intelligent caching (67% LLM cost savings)
 * - Context-aware analysis (uses workflow purpose)
 * - Business-focused language (not technical jargon)
 * - Actionable recommendations
 *
 * LLM Call Strategy:
 * - Check cache first (insights < 7 days old)
 * - Compare trend delta (if < 10% change, reuse cache)
 * - Only call Claude API when trends change significantly
 * - Result: ~1 LLM call per week for stable workflows
 *
 * @module lib/pilot/insight/BusinessInsightGenerator
 */

import { createLogger } from '@/lib/logger';
import type { SupabaseClient } from '@supabase/supabase-js';
import type { Agent } from '@/lib/repositories/types';
import type { ExecutionMetrics } from '../MetricsCollector';
import type { TrendMetrics, ExecutionMetricsRecord } from './TrendAnalyzer';
import { InsightRepository } from '@/lib/repositories/InsightRepository';
import Anthropic from '@anthropic-ai/sdk';

const logger = createLogger({ module: 'BusinessInsightGenerator', service: 'business-intelligence' });

/**
 * Business insight generated by LLM
 */
export interface BusinessInsight {
  type: 'volume_trend' | 'category_shift' | 'performance_issue' | 'operational_anomaly';
  severity: 'critical' | 'high' | 'medium' | 'low';
  title: string;
  description: string;
  business_impact: string;
  recommendation: string;
  confidence: number;  // 0.0-1.0
}

export class BusinessInsightGenerator {
  private supabase: SupabaseClient;
  private insightRepository: InsightRepository;
  private anthropic: Anthropic;

  constructor(supabase: SupabaseClient) {
    this.supabase = supabase;
    this.insightRepository = new InsightRepository(supabase);

    // Initialize Anthropic client
    this.anthropic = new Anthropic({
      apiKey: process.env.ANTHROPIC_API_KEY || process.env.CLAUDE_API_KEY,
    });
  }

  /**
   * Generate business insights from trend analysis
   *
   * Intelligent caching:
   * 1. Check for cached insight (< 7 days old)
   * 2. If found, compare trend delta
   * 3. If delta < 10%, reuse cache (NO LLM call)
   * 4. Otherwise, call Claude API
   *
   * @param agent - Agent configuration (includes workflow_purpose)
   * @param trends - Statistical trends from TrendAnalyzer
   * @param recentMetrics - Last 30 days of execution metrics
   * @param detectedPatterns - Technical patterns from detectors (for context)
   * @returns Business insights (1-3 key insights)
   */
  async generate(
    agent: Agent,
    trends: TrendMetrics,
    recentMetrics: ExecutionMetricsRecord[],
    detectedPatterns: any[] = []
  ): Promise<BusinessInsight[]> {
    const startTime = Date.now();

    logger.info({
      agentId: agent.id,
      trendDataPoints: trends.data_points,
      trendConfidence: trends.confidence,
    }, 'Starting business insight generation');

    // 1. Check for cached business insight
    const cachedInsight = await this.insightRepository.findExistingInsight(
      agent.id,
      'growth',  // Database constraint only allows 'growth' or 'data_quality'
      7 // days
    );

    if (cachedInsight) {
      logger.info({
        agentId: agent.id,
        cachedInsightId: cachedInsight.id,
        cachedAge: this.getCacheAge(cachedInsight),
      }, 'Found cached business insight');

      // 2. Compare current trends vs cached trends
      const cachedTrends = cachedInsight.pattern_data as unknown as TrendMetrics | undefined;

      if (cachedTrends) {
        const trendDelta = this.calculateTrendDelta(trends, cachedTrends);

        // 3. If trends haven't changed significantly, reuse cached insight
        if (trendDelta < 0.10) {  // Less than 10% change
          logger.info({
            agentId: agent.id,
            trendDelta: `${(trendDelta * 100).toFixed(1)}%`,
            cachedAge: this.getCacheAge(cachedInsight),
          }, 'âœ… Reusing cached business insight - trends stable (NO LLM CALL)');

          // Convert cached insight to BusinessInsight format
          return [{
            type: cachedInsight.insight_type as BusinessInsight['type'],
            severity: cachedInsight.severity as BusinessInsight['severity'],
            title: cachedInsight.title,
            description: cachedInsight.description,
            business_impact: cachedInsight.business_impact || '',
            recommendation: cachedInsight.recommendation || '',
            confidence: typeof cachedInsight.confidence === 'number'
              ? cachedInsight.confidence
              : 0.8,  // Default confidence for cached insights
          }];
        }

        logger.info({
          agentId: agent.id,
          trendDelta: `${(trendDelta * 100).toFixed(1)}%`,
          threshold: '10.0%',
        }, `Trends changed significantly - regenerating with LLM`);
      }
    }

    // 4. Trends changed significantly OR no cache - call LLM
    const generationTime = Date.now();

    // Build workflow context
    const workflowContext = this.buildWorkflowContext(agent);

    // Build LLM prompt
    const prompt = this.buildBusinessInsightPrompt(
      workflowContext,
      trends,
      recentMetrics,
      detectedPatterns
    );

    // Call Claude API
    const response = await this.callClaudeAPI(prompt);

    logger.debug({
      agentId: agent.id,
      llmResponsePreview: response.substring(0, 500),
    }, 'ðŸ“ LLM response received');

    // Parse and validate insights
    const insights = this.parseInsights(response);

    const llmTime = Date.now() - generationTime;
    const totalTime = Date.now() - startTime;

    logger.info({
      agentId: agent.id,
      insightsGenerated: insights.length,
      llmTimeMs: llmTime,
      totalTimeMs: totalTime,
      llmCalled: true,
      responseLength: response.length,
    }, insights.length === 0
      ? 'âœ… LLM correctly returned zero insights - workflow is healthy'
      : 'ðŸš€ Business insights generated via LLM');

    // Store insights in database for persistence
    await this.storeInsights(agent, insights, trends, recentMetrics);

    return insights;
  }

  /**
   * Build workflow context from agent metadata
   *
   * Priority order:
   * 1. created_from_prompt - User's original intent in natural language (BEST)
   * 2. workflow_purpose - If manually set by user
   * 3. description - Fallback
   * 4. agent_name - Last resort
   */
  private buildWorkflowContext(agent: Agent): string {
    // Priority 1: Use created_from_prompt (original user intent)
    if (agent.created_from_prompt) {
      return agent.created_from_prompt;
    }

    // Priority 2: Use workflow_purpose if available
    if (agent.workflow_purpose) {
      return agent.workflow_purpose;
    }

    // Priority 3: Fallback to name + description
    let context = agent.agent_name;
    if (agent.description) {
      context += `: ${agent.description}`;
    }

    return context;
  }

  /**
   * Build LLM prompt for business insight generation
   */
  private buildBusinessInsightPrompt(
    workflowContext: string,
    trends: TrendMetrics,
    recentMetrics: ExecutionMetrics[],
    detectedPatterns: any[] = []
  ): string {
    // Format recent metrics for prompt (privacy-safe, metadata only)
    // Note: Individual execution metrics less useful than trend summary
    const formattedMetrics = recentMetrics.slice(0, 30).map(m => ({
      items: m.total_items,  // Keep for reference, but trends use detected metric
      duration_ms: m.duration_ms,
      has_empty_results: m.has_empty_results,
      field_counts: m.items_by_field,
    }));

    // âœ… CRITICAL: Detected metric info for LLM context
    const detectedMetricInfo = trends.detected_metric
      ? `\n\nDETECTED BUSINESS METRIC:
- Step: "${trends.detected_metric.step.step_name}"
- Detection method: ${trends.detected_metric.detection_method}
- Confidence: ${(trends.detected_metric.confidence * 100).toFixed(0)}%
- Recent average: ${trends.metric_value_recent.toFixed(1)} items
- Historical average: ${trends.metric_value_historical.toFixed(1)} items
- Change: ${(((trends.metric_value_recent / trends.metric_value_historical) - 1) * 100).toFixed(1)}%

IMPORTANT: The above business metric (${trends.metric_value_recent.toFixed(1)} items) is the PRIMARY metric to discuss.
Do NOT use the total_items field from the raw metrics below - that sums ALL workflow steps and is misleading.`
      : '';

    return `You are a business intelligence analyst helping non-technical users understand their workflow automation.

# Workflow Purpose

${workflowContext}${detectedMetricInfo}

# Performance Data

## Historical Baseline
- Average items per run: ${trends.baseline.avg_items_per_execution.toFixed(1)}
- Average processing time: ${(trends.baseline.avg_duration_ms / 1000).toFixed(1)} seconds
- Typical patterns: ${JSON.stringify(trends.baseline.typical_category_distribution)}

## Detected Business Metric
${trends.detected_metric ? `
- Step being tracked: "${trends.detected_metric.step.step_name}"
- Detection method: ${trends.detected_metric.detection_method}
- Confidence: ${(trends.detected_metric.confidence * 100).toFixed(0)}%
- Recent average: ${trends.metric_value_recent.toFixed(1)} items per run
- Historical average: ${trends.metric_value_historical.toFixed(1)} items per run
- Change: ${trends.metric_value_recent > trends.metric_value_historical ? '+' : ''}${(((trends.metric_value_recent / trends.metric_value_historical) - 1) * 100).toFixed(1)}%
` : '- No specific business metric detected, using total items across all steps'}

## Recent Trends (Last 7 Days vs Historical)
- Volume change: ${trends.volume_change_7d > 0 ? '+' : ''}${(trends.volume_change_7d * 100).toFixed(1)}%
- Spike detected: ${trends.is_volume_spike ? 'YES' : 'NO'}
- Drop detected: ${trends.is_volume_drop ? 'YES' : 'NO'}
- Processing time change: ${trends.duration_change_7d > 0 ? '+' : ''}${(trends.duration_change_7d * 100).toFixed(1)}%
- Runs finding nothing: ${(trends.empty_result_rate * 100).toFixed(1)}%
- Failed runs: ${(trends.failure_rate * 100).toFixed(1)}%
- Data quality: ${trends.confidence} confidence (${trends.data_points} runs analyzed)
- Category distribution changes: ${JSON.stringify(trends.category_shift_7d)}

## Recent Execution Samples (Last ${formattedMetrics.length} runs - metadata only)
${JSON.stringify(formattedMetrics, null, 2)}

${detectedPatterns.length > 0 ? `
# Technical Patterns: ${detectedPatterns.map(p => `${p.insight_type} (${p.severity})`).join(', ')}

Note: These are flagged by automated detectors. Re-interpret based on workflow purpose.
` : ''}

# Analysis

${this.analyzeSituation(workflowContext, trends, detectedPatterns)}

# Your Task

Generate 1-3 business insights. MUST include at least one.

**Key principles:**
1. Interpret metrics based on workflow purpose (complaints/errors: low=good, leads/sales: high=good)
2. Use plain English (no jargon: tokens, ms, API, caching, metadata, validation)
3. Match severity to business impact (not technical detection)
4. Make recommendations specific and actionable

**Examples:**
- "6 seconds" NOT "6293ms"
- "Check Gmail filters" NOT "Review data collection steps"

# Output Format

Respond in JSON:
\`\`\`json
{
  "insights": [
    {
      "type": "scale_opportunity" | "data_validation_failed" | "performance_degradation" | "reliability_risk" | "automation_opportunity" | "cost_optimization",
      "severity": "critical" | "high" | "medium" | "low",
      "title": "Clear title in plain English (max 60 chars)",
      "description": "Plain English explanation of what's happening (1-2 sentences)",
      "business_impact": "Why this matters to the business (1 sentence)",
      "recommendation": "Specific action in plain English (1-2 sentences)",
      "confidence": 0.0-1.0
    }
  ]
}
\`\`\`

Generate insights now.`;
  }

  /**
   * Analyze the current situation and provide guidance to the LLM
   * This helps the LLM correctly interpret metrics based on workflow intent
   */
  private analyzeSituation(workflowContext: string, trends: TrendMetrics, detectedPatterns: any[] = []): string {
    const contextLower = workflowContext.toLowerCase();

    logger.debug({
      workflowContext: workflowContext.substring(0, 100),
      metricValue: trends.metric_value_recent,
      baseline: trends.metric_value_historical,
    }, 'ðŸ” Analyzing situation for LLM guidance');

    // Detect workflow type - what is being tracked?

    // UNDESIRABLE things (LOW count = GOOD, HIGH count = BAD)
    const trackingUndesirable =
      contextLower.includes('complaint') ||
      contextLower.includes('error') ||
      contextLower.includes('issue') ||
      contextLower.includes('problem') ||
      contextLower.includes('failure') ||
      contextLower.includes('bug') ||
      contextLower.includes('spam') ||
      contextLower.includes('fraud') ||
      contextLower.includes('violation') ||
      contextLower.includes('alert') ||
      contextLower.includes('incident') ||
      contextLower.includes('outage') ||
      contextLower.includes('downtime') ||
      contextLower.includes('refund') ||
      contextLower.includes('chargeback') ||
      contextLower.includes('cancellation');

    // DESIRABLE things (HIGH count = GOOD, LOW count = BAD)
    const trackingDesirable =
      contextLower.includes('lead') ||
      contextLower.includes('sale') ||
      contextLower.includes('opportunity') ||
      contextLower.includes('conversion') ||
      contextLower.includes('signup') ||
      contextLower.includes('registration') ||
      contextLower.includes('customer') ||
      contextLower.includes('subscriber') ||
      contextLower.includes('revenue') ||
      contextLower.includes('order') ||
      contextLower.includes('purchase') ||
      contextLower.includes('booking') ||
      contextLower.includes('enrollment') ||
      contextLower.includes('applicant') ||
      contextLower.includes('inquiry');

    const metricValue = trends.metric_value_recent;
    const baselineValue = trends.metric_value_historical;
    const change = metricValue - baselineValue;
    const changePercent = baselineValue > 0 ? (change / baselineValue) * 100 : 0;

    let interpretation = '';

    // Check if technical detector flagged "data_unavailable" pattern
    const hasDataUnavailablePattern = detectedPatterns.some(p =>
      p.insight_type === 'data_unavailable' ||
      p.insight_type === 'data_quality'
    );

    // Case 1: Tracking complaints/problems and finding zero/few
    if (trackingUndesirable && metricValue <= 1) {
      interpretation = `ðŸ“Š WORKFLOW TYPE: Tracking undesirable outcomes (complaints/problems/errors)
Current state: ${metricValue.toFixed(1)} items per run (baseline: ${baselineValue.toFixed(1)})

For this workflow type: LOW count = GOOD NEWS (healthy business state)

${hasDataUnavailablePattern ? `
Technical pattern detected: "data_unavailable" (flagged as critical)
Context: For complaint-tracking workflows, empty results often indicate HEALTHY state, not broken workflow.
Consider: Is zero complaints good news, or could the workflow be missing data?
` : ''}

Suggested insight approach:
- If workflow appears healthy: Celebratory message (LOW severity)
- If unsure about data quality: Gentle monitoring recommendation (LOW-MEDIUM severity)`;
    }
    // Case 2: Tracking complaints/problems and finding many (increase)
    else if (trackingUndesirable && metricValue > baselineValue && metricValue > 2) {
      interpretation = `ðŸ“Š WORKFLOW TYPE: Tracking undesirable outcomes (complaints/problems/errors)
Current state: ${metricValue.toFixed(1)} items per run (baseline: ${baselineValue.toFixed(1)}, change: +${changePercent.toFixed(1)}%)

For this workflow type: HIGH count = BAD NEWS (business issue)

Suggested severity: MEDIUM-HIGH (warrants investigation)`;
    }
    // Case 3: Tracking leads/opportunities and finding few (decrease)
    else if (trackingDesirable && metricValue < baselineValue * 0.7) {
      interpretation = `ðŸ“Š WORKFLOW TYPE: Tracking desirable outcomes (leads/opportunities/sales)
Current state: ${metricValue.toFixed(1)} items per run (baseline: ${baselineValue.toFixed(1)}, change: ${changePercent.toFixed(1)}%)

For this workflow type: LOW count = BAD NEWS (missing opportunities)

Suggested severity: MEDIUM-HIGH (investigate data source or business slowdown)`;
    }
    // Case 4: Tracking leads/opportunities and finding many (increase)
    else if (trackingDesirable && metricValue > baselineValue * 1.3) {
      interpretation = `ðŸ“Š WORKFLOW TYPE: Tracking desirable outcomes (leads/opportunities/sales)
Current state: ${metricValue.toFixed(1)} items per run (baseline: ${baselineValue.toFixed(1)}, change: +${changePercent.toFixed(1)}%)

For this workflow type: HIGH count = GOOD NEWS (business growing)

Suggested severity: LOW (celebratory message)`;
    }
    // Case 5: Neutral or stable operation
    else {
      interpretation = `ðŸ“Š WORKFLOW TYPE: ${trackingUndesirable ? 'Tracking undesirable outcomes' : trackingDesirable ? 'Tracking desirable outcomes' : 'General monitoring/processing'}
Current state: ${metricValue.toFixed(1)} items per run (baseline: ${baselineValue.toFixed(1)}, change: ${changePercent > 0 ? '+' : ''}${changePercent.toFixed(1)}%)

${Math.abs(changePercent) > 20 ? 'Notable change detected - may warrant investigation' : 'Stable operation within normal range'}

Look for other notable patterns: performance changes, failures, data quality issues`;
    }

    return interpretation;
  }

  /**
   * Call Claude API for insight generation
   */
  private async callClaudeAPI(prompt: string): Promise<string> {
    try {
      const response = await this.anthropic.messages.create({
        model: 'claude-3-haiku-20240307',  // Using Claude 3 Haiku (stable, cost-effective for insights)
        max_tokens: 1000,
        temperature: 0.3,  // Low temperature for consistency
        messages: [{
          role: 'user',
          content: prompt,
        }],
      });

      const content = response.content[0];
      if (content.type !== 'text') {
        throw new Error('Unexpected response type from Claude API');
      }

      logger.debug({
        usage: response.usage,
        stopReason: response.stop_reason,
      }, 'Claude API response received');

      return content.text;
    } catch (error) {
      logger.error({ err: error }, 'Failed to call Claude API');
      throw error;
    }
  }

  /**
   * Parse and validate LLM response
   */
  private parseInsights(response: string): BusinessInsight[] {
    try {
      // Extract JSON from response (might be wrapped in markdown code blocks)
      const jsonMatch = response.match(/```json\n([\s\S]+?)\n```/) ||
                       response.match(/\{[\s\S]+\}/);

      if (!jsonMatch) {
        logger.error({ response: response.substring(0, 500) }, 'No JSON found in LLM response');
        throw new Error('Invalid LLM response format - no JSON detected');
      }

      let jsonStr = jsonMatch[1] || jsonMatch[0];

      // Attempt to repair common JSON errors from LLM
      // 1. Remove trailing commas before closing braces/brackets
      jsonStr = jsonStr.replace(/,(\s*[}\]])/g, '$1');
      // 2. Fix unescaped quotes in strings (common LLM mistake)
      // 3. Remove any trailing content after final }
      const lastBrace = jsonStr.lastIndexOf('}');
      if (lastBrace !== -1) {
        jsonStr = jsonStr.substring(0, lastBrace + 1);
      }

      let parsed;
      try {
        parsed = JSON.parse(jsonStr);
      } catch (parseError: any) {
        logger.error({
          parseError: parseError.message,
          jsonStr: jsonStr.substring(0, 500),
          position: parseError.message.match(/position (\d+)/)?.[1],
        }, 'JSON parse failed - attempting repair');

        // Last resort: try to extract just the insights array
        const insightsMatch = jsonStr.match(/"insights":\s*\[([\s\S]+)\]/);
        if (insightsMatch) {
          jsonStr = `{"insights":[${insightsMatch[1]}]}`;
          parsed = JSON.parse(jsonStr);
          logger.info('Successfully repaired JSON by extracting insights array');
        } else {
          throw parseError;
        }
      }

      if (!parsed.insights || !Array.isArray(parsed.insights)) {
        logger.error({ parsed }, 'Invalid insight structure');
        throw new Error('Response missing insights array');
      }

      // Validate each insight
      const validInsights = parsed.insights.filter((insight: any) => {
        return (
          insight.type &&
          insight.severity &&
          insight.title &&
          insight.description &&
          insight.business_impact &&
          insight.recommendation &&
          typeof insight.confidence === 'number'
        );
      });

      // Allow empty insights array (workflow is healthy, no insights needed)
      if (validInsights.length === 0 && parsed.insights.length === 0) {
        logger.info('LLM returned zero insights - workflow is healthy, no issues to report');
        return [];
      }

      if (validInsights.length === 0 && parsed.insights.length > 0) {
        logger.error({ parsed }, 'No valid insights in response (invalid structure)');
        throw new Error('No valid insights generated - all insights failed validation');
      }

      logger.info({
        totalInsights: parsed.insights.length,
        validInsights: validInsights.length,
      }, 'Insights parsed and validated');

      return validInsights as BusinessInsight[];
    } catch (error: any) {
      logger.error({
        err: error,
        errorMessage: error.message,
        responsePreview: response.substring(0, 500),
      }, 'Failed to parse LLM response - returning empty array');

      // Return empty array instead of throwing - insights are non-critical
      // The calling code will handle empty results gracefully
      return [];
    }
  }

  /**
   * Calculate how much trends have changed since cached insight
   *
   * Returns 0.0-1.0 (0% to 100% change)
   */
  private calculateTrendDelta(current: TrendMetrics, cached: TrendMetrics): number {
    const deltas = [
      Math.abs(current.volume_change_7d - (cached.volume_change_7d || 0)),
      Math.abs(current.duration_change_7d - (cached.duration_change_7d || 0)),
      Math.abs(current.empty_result_rate - (cached.empty_result_rate || 0)),
      Math.abs(current.failure_rate - (cached.failure_rate || 0)),
    ];

    // Return max delta (most significant change)
    return Math.max(...deltas);
  }

  /**
   * Get cache age in hours
   */
  private getCacheAge(insight: { created_at: string }): string {
    const ageMs = Date.now() - new Date(insight.created_at).getTime();
    const ageHours = ageMs / (1000 * 60 * 60);

    if (ageHours < 1) {
      return `${Math.round(ageMs / (1000 * 60))} minutes`;
    } else if (ageHours < 24) {
      return `${Math.round(ageHours)} hours`;
    } else {
      return `${Math.round(ageHours / 24)} days`;
    }
  }

  /**
   * Store business insights in database for persistence
   *
   * Stores insights in the same execution_insights table as technical insights
   * Category: 'business_intelligence'
   * Pattern data: TrendMetrics for future comparison
   */
  private async storeInsights(
    agent: Agent,
    insights: BusinessInsight[],
    trends: TrendMetrics,
    recentMetrics: ExecutionMetricsRecord[]
  ): Promise<void> {
    try {
      // Get user_id from agent
      const { data: agentData } = await this.supabase
        .from('agents')
        .select('user_id')
        .eq('id', agent.id)
        .single();

      if (!agentData) {
        logger.error({ agentId: agent.id }, 'Agent not found - cannot store insights');
        return;
      }

      // Get execution IDs from recent metrics
      const executionIds = recentMetrics.map(m => m.execution_id);

      // Store each insight
      for (const insight of insights) {
        // Convert numeric confidence (0.0-1.0) to ConfidenceMode string
        const confidenceMode = this.convertConfidenceToMode(insight.confidence, trends.data_points);

        const stored = await this.insightRepository.create({
          user_id: agentData.user_id,
          agent_id: agent.id,
          execution_ids: executionIds,
          insight_type: insight.type,
          category: 'growth',  // Database constraint only allows 'growth' or 'data_quality'
          severity: insight.severity,
          confidence: confidenceMode,  // Convert to ConfidenceMode: observation|early_signals|emerging_patterns|confirmed
          title: insight.title,
          description: insight.description,
          business_impact: insight.business_impact,
          recommendation: insight.recommendation,
          pattern_data: trends as unknown as any,  // Store TrendMetrics for future comparison
          metrics: {
            total_executions: recentMetrics.length,
            affected_executions: recentMetrics.length,
            pattern_frequency: 1.0,
            first_occurrence: recentMetrics[recentMetrics.length - 1]?.executed_at,
            last_occurrence: recentMetrics[0]?.executed_at,
          },
          status: 'new',
        });

        if (stored) {
          logger.info({
            agentId: agent.id,
            insightId: stored.id,
            insightType: insight.type,
            severity: insight.severity,
          }, 'âœ… Business insight stored in database');
        }
      }
    } catch (error) {
      // Non-fatal - insights were already generated
      logger.error({
        err: error,
        agentId: agent.id,
      }, 'Failed to store business insights (non-fatal)');
    }
  }

  /**
   * Convert numeric confidence (0.0-1.0) to ConfidenceMode string
   * Based on confidence score and data points available
   */
  private convertConfidenceToMode(
    confidence: number,
    dataPoints: number
  ): 'observation' | 'early_signals' | 'emerging_patterns' | 'confirmed' {
    // Use data points as primary indicator, confidence as secondary
    if (dataPoints >= 20) {
      return 'confirmed';  // 20+ data points = confirmed trends
    } else if (dataPoints >= 10) {
      return 'emerging_patterns';  // 10-19 data points = strong patterns
    } else if (dataPoints >= 4) {
      return 'early_signals';  // 4-9 data points = early signals
    } else {
      return 'observation';  // 1-3 data points = just observation
    }
  }

  /**
   * Generate insights from detected patterns only (for agents with < 7 executions)
   * This replaces InsightGenerator - same workflow context, better interpretation
   *
   * @param agent - Agent configuration
   * @param patterns - Detected patterns from DataQualityDetector, ReliabilityDetector, etc.
   * @param confidence_mode - Confidence based on execution count
   * @param execution_count - Number of executions analyzed
   * @returns Business insights (pattern-based, no trends yet)
   */
  async generateFromPatterns(
    agent: Agent,
    patterns: any[],  // DetectedPattern from insight/types.ts
    confidence_mode: string,
    execution_count: number
  ): Promise<BusinessInsight[]> {
    if (patterns.length === 0) {
      return [];
    }

    logger.info({
      agentId: agent.id,
      patternCount: patterns.length,
      executionCount: execution_count,
    }, 'Generating insights from patterns only (no trends yet)');

    const workflowContext = this.buildWorkflowContext(agent);

    // Build prompt for pattern-based insights
    const prompt = this.buildPatternInsightPrompt(
      workflowContext,
      patterns,
      confidence_mode,
      execution_count
    );

    // Call Claude API
    const response = await this.callClaudeAPI(prompt);

    // Parse insights
    const insights = this.parseInsights(response);

    logger.info({
      agentId: agent.id,
      insightsGenerated: insights.length,
    }, 'Pattern-based insights generated');

    return insights;
  }

  /**
   * Build LLM prompt for pattern-based insights (no trends available yet)
   */
  private buildPatternInsightPrompt(
    workflowContext: string,
    patterns: any[],
    confidence_mode: string,
    execution_count: number
  ): string {
    // Format patterns for prompt
    const formattedPatterns = patterns.map(p => ({
      type: p.insight_type,
      severity: p.severity,
      frequency: `${Math.round((p.metrics?.pattern_frequency || 0) * 100)}%`,
      affected: `${p.metrics?.affected_executions || 0}/${p.metrics?.total_executions || 0}`,
      details: p.pattern_data,
    }));

    return `You are a business intelligence analyst helping non-technical users understand their workflow automation.

# Workflow Purpose

${workflowContext}

# Detected Patterns (${execution_count} executions analyzed)

${formattedPatterns.map((p, i) => `
## Pattern ${i + 1}: ${p.type}
- Severity (from detector): ${p.severity}
- Frequency: ${p.frequency} of runs
- Affected: ${p.affected} executions
- Details: ${JSON.stringify(p.details, null, 2)}
`).join('\n')}

# Your Task

Generate 1-3 actionable insights from the patterns above.

## Critical Instructions

**1. Understand the workflow's purpose**
Read "Workflow Purpose" carefully. What is this workflow designed to do?

**2. Interpret patterns based on intent**
- Don't blindly use the detector's severity - it's rule-based and doesn't know workflow context
- Consider whether the pattern represents success or a problem based on workflow purpose
- Empty results might be GOOD (no problems found) or BAD (workflow broken)

**3. Write for non-technical users - NO JARGON**
Never use: "tokens", "ms", "field names", "has_priority field", "API", "caching", "metadata"
Use plain English: "processing time", "records", "information", "check if X changed"

**4. Make recommendations specific and actionable**
Tell them exactly what to do: "Check your Gmail search filters" not "Review data collection"

**5. Data confidence: ${confidence_mode}**
With only ${execution_count} executions, use tentative language:
- "observation": "We noticed..."
- "early_signals": "We're seeing signs..."

# Output Format

\`\`\`json
{
  "insights": [
    {
      "type": "scale_opportunity" | "data_validation_failed" | "performance_degradation" | "reliability_risk" | "automation_opportunity" | "cost_optimization",
      "severity": "critical" | "high" | "medium" | "low",
      "title": "Clear title in plain English (max 60 chars)",
      "description": "Plain English explanation (1-2 sentences)",
      "business_impact": "Why this matters (1 sentence)",
      "recommendation": "Specific action in plain English (1-2 sentences)",
      "confidence": 0.0-1.0
    }
  ]
}
\`\`\`

Generate insights now based on the workflow purpose and detected patterns.`;
  }
}
